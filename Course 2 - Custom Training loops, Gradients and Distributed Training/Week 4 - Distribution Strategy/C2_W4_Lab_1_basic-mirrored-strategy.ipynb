{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWuM08KoQi6A"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-3-public/blob/main/Course%202%20-%20Custom%20Training%20loops%2C%20Gradients%20and%20Distributed%20Training/Week%204%20-%20Distribution%20Strategy/C2_W4_Lab_1_basic-mirrored-strategy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_qRb-tEQi6B"
      },
      "source": [
        "# Mirrored Strategy: Basic\n",
        "\n",
        "In this ungraded lab you'll go through some of the basics of applying Mirrored Strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHsMZcf6Qi6B"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TkUjfmKkflCd"
      },
      "outputs": [],
      "source": [
        "# Import TensorFlow and TensorFlow Datasets\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa9ekvkLQi6C"
      },
      "source": [
        "Load the MNIST dataset and split it into training and test chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQN-PtIGgFtH",
        "outputId": "e52989db-3a03-4dbe-95d1-d36ccf6b8633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Variant folder data/mnist/3.0.1 has no dataset_info.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to data/mnist/3.0.1...\n",
            "Dataset mnist downloaded and prepared to data/mnist/3.0.1. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset we'll use for this lab\n",
        "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True, data_dir='./data')\n",
        "\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od74gR0PQi6D"
      },
      "source": [
        "Next, you define `strategy` using the `MirroredStrategy()` class. Print to see the number of devices available.\n",
        "\n",
        "**Note:**\n",
        "- If you are running this on Coursera you'll see it gives a warning about no presence of GPU devices.\n",
        "- If you are running this in Colab make sure you have selected your `runtime` to be `GPU` for it to detect it.\n",
        "- In both these cases you'll see there's only 1 device that is available.  \n",
        "- One device is sufficient for helping you understand the these distribution strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCsDqWnDgNHr",
        "outputId": "85344045-c25d-477a-be77-077357faddda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n"
          ]
        }
      ],
      "source": [
        "# Define the strategy to use and print the number of devices found\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1aq1g7TQi6D"
      },
      "source": [
        "Next, you create your training and test examples, define your batch size and also define `BATCH_SIZE_PER_REPLICA` which is the distribution you are making for each available device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p1xWxKcnhar9"
      },
      "outputs": [],
      "source": [
        "# Get the number of examples in the train and test sets\n",
        "num_train_examples = info.splits['train'].num_examples\n",
        "num_test_examples = info.splits['test'].num_examples\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "# Use for Mirrored Strategy\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "# Use for No Strategy\n",
        "# BATCH_SIZE = BATCH_SIZE_PER_REPLICA * 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABLp6lImQi6E"
      },
      "source": [
        "A mapping function which normalizes your images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aPIU8E7BhyYq"
      },
      "outputs": [],
      "source": [
        "# Function for normalizing the image\n",
        "def scale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255\n",
        "\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXnYXQ0GQi6E"
      },
      "source": [
        "Next you create your training and evaluation datesets in the batch size you want by shuffling through your buffer size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ByTZB2AYh0nA"
      },
      "outputs": [],
      "source": [
        "# Set up the train and eval data set\n",
        "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad2iaYW6Qi6E"
      },
      "source": [
        "For your model to follow the strategy, define your model within the strategy's scope.\n",
        "- Run all the cells below and notice the results.\n",
        "- Afterwards comment out `with strategy.scope():` and run everything again, without the strategy.\n",
        "Then you can compare the results.\n",
        "The important thing to notice and compare is the time taken for each epoch to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rRzY5ojh51B",
        "outputId": "9de78ea4-c5c5-405f-89e8-a10a37d8d6d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.8860 - loss: 0.3947\n",
            "Epoch 2/12\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9791 - loss: 0.0713\n",
            "Epoch 3/12\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9858 - loss: 0.0469\n",
            "Epoch 4/12\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9899 - loss: 0.0349\n",
            "Epoch 5/12\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0262\n",
            "Epoch 6/12\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9938 - loss: 0.0201\n",
            "Epoch 7/12\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 0.0149\n",
            "Epoch 8/12\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9960 - loss: 0.0114\n",
            "Epoch 9/12\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 0.0106\n",
            "Epoch 10/12\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0063\n",
            "Epoch 11/12\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0073\n",
            "Epoch 12/12\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0064\n"
          ]
        }
      ],
      "source": [
        "# Use for Mirrored Strategy -- comment out `with strategy.scope():` and deindent for no strategy\n",
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  model.fit(train_dataset, epochs=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NWOJWLENphod"
      },
      "outputs": [],
      "source": [
        "# no strategy\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_dataset, epochs=12)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Basic Mirrored Strategy",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}